{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use to run on colab to take advantage of parallel processing on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from datetime import datetime\n",
    "from transformers import pipeline\n",
    "\n",
    "def flatten_restaurant_reviews(json_data):\n",
    "    \"\"\"\n",
    "    Flatten restaurant reviews from a nested JSON structure into a pandas DataFrame.\n",
    "    Each row will contain a review with its associated restaurant ID.\n",
    "    \"\"\"\n",
    "    flattened_data = []\n",
    "    \n",
    "    # Iterate through each restaurant and its reviews\n",
    "    for restaurant_id, reviews in json_data.items():\n",
    "        for review in reviews:\n",
    "            # Create a flat record with restaurant_id and all review data\n",
    "            flat_record = {\n",
    "                'restaurant_id': restaurant_id,\n",
    "                'review_id': review['id'],\n",
    "                'rating': review['rating'],\n",
    "                'text': review['text'],\n",
    "                'time_created': review['time_created'],\n",
    "                'user_id': review['user']['id'],\n",
    "                'user_name': review['user']['name'],\n",
    "            }\n",
    "            flattened_data.append(flat_record)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    return pd.DataFrame(flattened_data)\n",
    "\n",
    "def add_user_stats(reviews_df):\n",
    "    \"\"\"Add user-level statistics as features\"\"\"\n",
    "    # Calculate average rating per user\n",
    "    user_avg_rating = reviews_df.groupby('user_id')['rating'].mean()\n",
    "    reviews_df['user_avg_rating'] = reviews_df['user_id'].map(user_avg_rating)\n",
    "    \n",
    "    # Calculate rating deviation (how this rating differs from user's average)\n",
    "    reviews_df['rating_deviation'] = reviews_df['rating'] - reviews_df['user_avg_rating']\n",
    "    \n",
    "    # Count reviews per user\n",
    "    user_review_count = reviews_df.groupby('user_id')['review_id'].count()\n",
    "    reviews_df['user_review_count'] = reviews_df['user_id'].map(user_review_count)\n",
    "    \n",
    "    # Calculate standard deviation of user ratings (consistent vs variable rater)\n",
    "    user_rating_std = reviews_df.groupby('user_id')['rating'].std()\n",
    "    reviews_df['user_rating_std'] = reviews_df['user_id'].map(user_rating_std)\n",
    "    \n",
    "    return reviews_df\n",
    "\n",
    "def add_recency_score(reviews_df):\n",
    "    reviews_df['time_created'] = pd.to_datetime(reviews_df['time_created'])\n",
    "    current_time = datetime.now()\n",
    "    reviews_df['days_since_review'] = (current_time - reviews_df['time_created']).dt.total_seconds() / (60*60*24)\n",
    "    max_days = reviews_df['days_since_review'].max()\n",
    "    reviews_df['recency_score'] = 1 - (reviews_df['days_since_review'] / max_days)\n",
    "\n",
    "    return reviews_df\n",
    "\n",
    "def add_normalized_rating(reviews_df):\n",
    "    min_rating = reviews_df['rating'].min()\n",
    "    max_rating = reviews_df['rating'].max()\n",
    "\n",
    "    # Min-max normalization\n",
    "    reviews_df['normalized_rating'] = (reviews_df['rating'] - min_rating) / max_rating \n",
    "    \n",
    "    return reviews_df\n",
    "\n",
    "def add_weighted_score(reviews_df, alpha=0.5):\n",
    "    reviews_df['weighted_score'] = alpha * reviews_df['normalized_rating'] + (1 - alpha) * reviews_df['recency_score']\n",
    "\n",
    "    return reviews_df\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "def add_bert_sentiment(reviews_df):\n",
    "    \"\"\"\n",
    "    Add sentiment scores using a pre-trained BERT model.\n",
    "    Uses Hugging Face pipeline for sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "    # Convert the DataFrame to a Hugging Face Dataset\n",
    "    dataset = Dataset.from_pandas(reviews_df)\n",
    "\n",
    "    # Initialize the sentiment analysis pipeline with GPU support\n",
    "    sentiment_analyzer = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=\"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "        device=device  # Use GPU if available, otherwise fallback to CPU\n",
    "    )\n",
    "\n",
    "    # Define a function to apply the sentiment analysis in batches\n",
    "    def analyze_sentiment(batch):\n",
    "        sentiments = sentiment_analyzer(batch['text'])\n",
    "        batch['bert_sentiment'] = [sent['label'] for sent in sentiments]\n",
    "        batch['bert_score'] = [sent['score'] for sent in sentiments]\n",
    "        return batch\n",
    "\n",
    "    # Apply the function to the dataset in batches\n",
    "    dataset = dataset.map(analyze_sentiment, batched=True, batch_size=16)\n",
    "\n",
    "    # Convert the dataset back to a DataFrame\n",
    "    reviews_df = dataset.to_pandas()\n",
    "\n",
    "    # Map BERT output to positive, neutral, negative\n",
    "    def map_sentiment(label):\n",
    "        if label in ['4 stars', '5 stars']:\n",
    "            return 'positive'\n",
    "        elif label == '3 stars':\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "\n",
    "    # Calculate a weighted sentiment score (similar to compound)\n",
    "    def calculate_weighted_score(label, score):\n",
    "        stars = int(label[0])  # Extract the numeric part from '4 stars', '5 stars', etc.\n",
    "        return (stars / 5) * score\n",
    "\n",
    "    # Add the mapped sentiment and weighted score to the DataFrame\n",
    "    reviews_df['mapped_sentiment'] = reviews_df['bert_sentiment'].apply(map_sentiment)\n",
    "    reviews_df['weighted_score'] = reviews_df.apply(lambda x: calculate_weighted_score(x['bert_sentiment'], x['bert_score']), axis=1)\n",
    "\n",
    "    return reviews_df\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_reviews(reviews_df):\n",
    "\n",
    "    # initialize extract textual features from the reviews posted by users\n",
    "    # not useful\n",
    "    # text_feature_extractor = TextFeatureExtractor(reviews_df=reviews_df)\n",
    "\n",
    "    # did not add aspect sentiments, topic modelling and user stats because they have harder\n",
    "    # assumptions to make also because that is added complexity and may not yield results for this \n",
    "    # current first iteration of project\n",
    "\n",
    "    reviews_df = add_bert_sentiment(reviews_df)\n",
    "    reviews_df = add_recency_score(reviews_df)\n",
    "    reviews_df = add_normalized_rating(reviews_df)\n",
    "    reviews_df = add_weighted_score(reviews_df)\n",
    "    \n",
    "    return reviews_df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # save file reviews.json to drive first\n",
    "    with open(r'/content/drive/MyDrive/reviews.json', 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 2. Convert to DataFrame\n",
    "    reviews_df = flatten_restaurant_reviews(data)\n",
    "    reviews_df = preprocess_reviews(reviews_df)\n",
    "\n",
    "\n",
    "    # save the file\n",
    "    reviews_df.to_pickle('data/processed_review_data.pkl')\n",
    "    print(reviews_df.head())\n",
    "    print(reviews_df.columns)\n",
    "\n",
    "# download the file locally afterprocessing"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
